{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tF6NxiM3Uod",
        "outputId": "e52e3a3f-29f5-4251-c438-55043c30816b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "images_path = \"/content/drive/MyDrive/images.tar\"\n",
        "\n",
        "dataset_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
        "\n",
        "res = requests.get(url=dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(images_path,mode='wb') as f:  \n",
        "    f.write(res.content)"
      ],
      "metadata": {
        "id": "Bf_HGIHTQhmI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "def un_tar(file_name):  \n",
        "      tar = tarfile.open(file_name)  \n",
        "      names = tar.getnames()  \n",
        "      if os.path.isdir(file_name + \"_files\"):  \n",
        "          pass  \n",
        "      else:  \n",
        "          os.mkdir(file_name + \"_files\")  \n",
        "      for name in names:  \n",
        "          tar.extract(name, file_name + \"_files/\")  \n",
        "      tar.close()  \n",
        "un_tar(images_path)\n"
      ],
      "metadata": {
        "id": "hfSfptPpRjTI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar\"\n",
        "\n",
        "classification_path = \"/content/drive/MyDrive/lists.tar\"\n",
        "\n",
        "classification_res = requests.get(url=classification_url)\n",
        "\n",
        "with open(classification_path,mode='wb') as f:  \n",
        "    f.write(classification_res.content)"
      ],
      "metadata": {
        "id": "qBXTwmIsSoQc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "un_tar(classification_path)"
      ],
      "metadata": {
        "id": "wBJnWXlZTPkF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as scio\n",
        "import shutil\n",
        "\n",
        "# load the test and train classification list\n",
        "test_path = \"/content/drive/MyDrive/lists.tar_files/test_list.mat\"\n",
        "train_path = \"/content/drive/MyDrive/lists.tar_files/train_list.mat\"\n",
        "\n",
        "# images path (untar by images.tar)\n",
        "path_img = \"/content/drive/MyDrive/images.tar_files/\"\n",
        "if not os.path.exists(path_img+\"test\"):\n",
        "    os.makedirs(path_img+\"test\")\n",
        "if not os.path.exists(path_img+\"train\"):\n",
        "    os.makedirs(path_img+\"train\")\n",
        "\n",
        "test_data = scio.loadmat(test_path)\n",
        "\n",
        "# create test folder\n",
        "for t in test_data[\"labels\"]:\n",
        "    if not os.path.exists(path_img+\"test/\"+str(t[0])):\n",
        "        os.makedirs(path_img+\"test/\"+str(t[0]))\n",
        "train_data = scio.loadmat(train_path)\n",
        "\n",
        "# create train folder\n",
        "for t in train_data[\"labels\"]:\n",
        "    if not os.path.exists(path_img+\"train/\"+str(t[0])):\n",
        "        os.makedirs(path_img+\"train/\"+str(t[0]))\n",
        "\n",
        "# classify the test images to test folder\n",
        "for t in range(len(test_data[\"file_list\"])):\n",
        "    source_path = (path_img+\"Images/\"+test_data[\"file_list\"][t][0][0])\n",
        "    target_path = (path_img+\"test/\"+str(test_data[\"labels\"][t][0])+\"/\"+test_data[\"file_list\"][t][0][0].split(\"/\", 1)[1])\n",
        "    shutil.copyfile(source_path,target_path)\n",
        "\n",
        "# classify the train images to test folder\n",
        "for t in range(len(train_data[\"file_list\"])):\n",
        "    source_path = (path_img+\"Images/\"+train_data[\"file_list\"][t][0][0])\n",
        "    target_path = (path_img+\"train/\"+str(train_data[\"labels\"][t][0])+\"/\"+train_data[\"file_list\"][t][0][0].split(\"/\", 1)[1])\n",
        "    shutil.copyfile(source_path,target_path)"
      ],
      "metadata": {
        "id": "Ru7kWSvDTY0s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from skimage.transform import resize\n",
        "from IPython.display import SVG\n",
        "from tensorflow import keras\n",
        "from keras import applications\n",
        "from keras import optimizers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import layers, models\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/images.tar_files/test\"\n",
        "train_path = \"/content/drive/MyDrive/images.tar_files/train\"\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "channels = 3\n",
        "batch_size = 64\n",
        "num_images = 100\n",
        "image_arr_size = img_width * img_height * channels"
      ],
      "metadata": {
        "id": "o3rVnBG9UcoE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    shear_range= 0.2,\n",
        "    zoom_range= 0.2,\n",
        "    horizontal_flip= True,\n",
        "    rotation_range= 20,\n",
        "    width_shift_range= 0.2,\n",
        "    height_shift_range= 0.2,\n",
        "    validation_split=0.2,\n",
        "\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size= (img_width, img_height),\n",
        "    color_mode= 'rgb',\n",
        "    batch_size= batch_size,\n",
        "    class_mode= 'categorical',\n",
        "    subset='training',\n",
        "    shuffle= True,\n",
        "    seed= 1337\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size= (img_width, img_height),\n",
        "    color_mode= 'rgb',\n",
        "    batch_size= batch_size,\n",
        "    class_mode= 'categorical',\n",
        "    subset='validation',\n",
        "    shuffle= True,\n",
        "    seed= 1337\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYp6M7RpUwbq",
        "outputId": "7c70f376-a50e-4365-9c24-e93add195fb3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9600 images belonging to 120 classes.\n",
            "Found 2400 images belonging to 120 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_generator.class_indices)\n",
        "train_labels = train_generator.classes\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "valid_labels = valid_generator.classes\n",
        "valid_labels = to_categorical(valid_labels, num_classes=num_classes)\n",
        "nb_train_samples = len(train_generator.filenames)\n",
        "nb_valid_samples = len(valid_generator.filenames)"
      ],
      "metadata": {
        "id": "lDMXgf5UUysx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1/255.0)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "                                    test_path,\n",
        "                                    target_size=(img_width, img_height),\n",
        "                                    color_mode= 'rgb',\n",
        "                                    batch_size=batch_size,\n",
        "                                    class_mode= 'categorical',\n",
        "                                    shuffle=True,)\n",
        "test_generator.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7gwWDa0U0uZ",
        "outputId": "31836aa0-8ad1-4335-f27f-811ca1e69682"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8580 images belonging to 120 classes.\n"
          ]
        }
      ]
    }
  ]
}